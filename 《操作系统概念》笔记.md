# Part One Overview

## Chapter 1 Introduction

Android不是操作系统。

__操作系统特性__：

1. 抽象(Abstraction)<br/>
   Abstraction is a well-understood interface that hides all the details within a subsystem.
2. 虚拟化(Virtualization)
   * The OS takes a physical resource and transforms it into a more general, powerful, and easy-to-use virtual form of itself.
   * It creates an illusion that each program exclusively owns the physical resource.
3. 并发(Concurrency)<br/>
   Concurrent running of multiple applications.
4. 持久(Persistence)<br/>
   The file system is used to persistence.

__操作系统历史__

* Simple Batch System 单道批处理<br/>
  特点：

  * 用户独占全机资源
  * 程序运行前准备时间过长
  * 人机速度不匹配

  拥有早期的原始的操作系统：驻留监督程序(Resident monitor):

  * initial control in monitor
  * control transfers to job
  * when job completes control transfers back to monitor

* Multiprogrammed Batch System 多道批处理<br/>
  第一次操作系统需要帮用户做决策，即任务调度。<br/>
  操作系统特性：

  * I/O routine must be supplied by OS.
  * Memory management<br/>
    The system must allocate the memory to several jobs.
  * CPU scheduling<br/>
    The system must choose among several jobs ready to run
  * Allocation of devices.
  * Job scheduling<br/>
    The system must choose among jobs ready to be brought into memory.

  优点：CPU利用率大大提高<br/>
  缺点：用户无控制权，无交互性，延迟大<br/>
  引入多道批处理技术的根本目的：<br/>
  提高CPU利用率，充分发挥并行性。这包括：程序之间，设备之间，设备与CPU之间均并行工作。<br/>
  【注意】I/O任务可以并行执行，CPU任务不可以并行执行

* Time-sharing or Multi-tasking Systems 分时

  * Interactive computer system provides direct communication between user and the system.
    * The user gives instructions to the system directly, waits for immediately results. __Response time should be short__.
    * When the operating system finishes the execution of one command, it seeks the next control statement from the user's keyboard.
  * Time-sharing operating system allows many users to share the computer simultaneously.
    * Switches rapidly from one user to the next.
    * Gives users the impression: __The entire computer system is dedicated for my use__.
  * The CPU is multiplexed among several jobs that are kept in memory and on disk.
  * To obtain a reasonable response time, a job needs to be swapped in and out of memory on the disk (virtual memory).
  * Disk management must be provided
  * Sophisticated CPU-scheduling schemes are required for concurrent execution
  * Job synchronization mechanisms are needed
  * It may ensure that jobs do not get stuck in a deadlock

* Parallel Systems and Distributed System

## Chapter 2 Operating-System Operation

操作系统运行的特征：
* I/O设备和CPU可以并行执行
* 每个设备控制器都管理一个特殊的设备类型
* 每个设备管理器都有一个本地缓冲区
* CPU将主存中的数据和控制器缓冲区中的数据进行交换
* I/O是从设备向控制器的缓冲区
* 设备控制器通过引起中断来提醒CPU它已完成操作

__中断__
An event that requires the attention of the OS is an interrupt.

An interrupt generated by software (i.e., division by 0, page fault, debug breakpoint) is usually referred to as a __trap__.

Modern operating systems are __interrupt driven__(中断驱动的), meaning the OS is in action only if an interrupt occurs, namely:

* The OS is activated by an interrupt.
* The executing program is suspended.
* Control is transferred to the OS.
* Program continues when the service completes.

中断的功能：

* 中断通过中断向量，将控制转移到中断服务程序中。中断向量包括了所有服务程序的地址
* 中断架构必须保存中断指令的地址
* 在一个中断的处理中，新来的中断会被冻结来防止中断丢失

中断的处理：

* 操作系统通过保存寄存器和程序指针来保存了CPU的状态
* 判断是哪种中断
  * 轮询
  * 向量中断系统
* 不同段的代码决定每种中断应采用哪种行为

从用户的角度看：

* 同步I/O<br/>
  在I/O启动后，只有在I/O完成后控制权才会交还给用户程序
  * `Wait`指令让用户进程空闲直到下一个中断
  * Wait loop
  * 同时至多只有一个I/O请求
* 异步I/O<br/>
  在I/O启动后，控制权不需要等待I/O结束就能交还给用户程序

DMA

* 用于高速I/O设备能以接近主存速度传输信息
* 设备控制器不需要CPU的干预，从缓冲区将数据块直接传输到主存之中
* 每个数据块只产生一个中断
* CPU把磁盘地址、用于存储数据块的主存地址和数据块长度交给控制器，然后CPU回到工作

双态(Dual Mode)

* 用户态
* 内核态

System Calls<br/>
System calls提供了一个在运行的程序与操作系统之间的接口

* 一般是汇编语言指令
* 用于替代汇编语言的语言可以直接调用system calls(如C, C++)

一个System call从软件中断（陷落）执行

系统调用参数传递的方式

* 将参数传入寄存器
* 将参数存入内存块，将内存块的地址传入寄存器<br/>
  Linux及Solaris使用这种方式
* 将参数压入程序栈中，并由操作系统弹栈

操作系统结构

* Monolithic kernel(单内核、宏内核、巨内核)<br/>
  例子：Unix, Linux<br/>
  每个应用都有其硬件地址空间；操作系统也有其硬件地址空间；硬件由操作系统管理<br/>
  __优点__

  * 安全
  * 减少了由集成带来的性能损耗

  __缺点__

  * 无法定制

* Microkernel system structure<br/>
  每个应用都有其硬件地址空间；每个操作系统服务（位于用户态）都有其地址空间；微内核提供简单的抽象，提供地址空间和进程间通信<br/>
  __优点__

  * 扩展微内核更加容易
  * 更容易将操作系统移植到新的架构中
  * 更加可靠
  * 更加安全

  __缺点__

  * 性能损失

* Hybrid kernel, and Monolithic kernel with modules<br/>
  例子：Windows，macOS

操作系统结构设计的目的

* 保护
* 性能
* 灵活
* 可扩展性<br/>
  如果硬件资源升级，那么性能就可以提升
* 敏捷
* 响应性

虚拟化<br/>
虚拟化指的是建立一个虚拟化的版本。

虚拟机<br/>
一个虚拟机系统提供了等同于硬件的接口。

虚拟机的实现方法

* Virtual machine monitor(VMM)
* Hosted hypervisor<br/>
  将硬件和宿主操作系统内核都看作硬件

# Part Two Process Management

## Chapter 3 Processes

### Process Concept

Process VS Program:

* A program is lifeless, the OS makes it running (as a process)
* A process can be viewed as a running program with machine states

进程的运行状态指的包括

* 内存<br/>
  地址空间
* 寄存器<br/>
  程序计数器、指令指针<br/>
  栈指针，帧指针<br/>
  处理器的其他寄存器
* I/O信息

进程的运行状态

* new
* running
* waiting
* ready
  The process is waiting to be assigned to a processor
* terminated

|| new  | ready | running | waiting | terminating |
| ---- | ---- | ----- | ------- | ------- | ----------- |
| new |    | admitted |         |         |             |
| ready |||scheduler dispatch|||
| running ||interrupt||I/O or event waiting|exit|
| waiting ||I/O or event completion||||
| terminating ||||||

__进程控制块(PCB)<br/>__
和每个进程相关的信息

* Pointer
  pointer to each PCB
* Process state
* Program counter
* CPU registers
* CPU scheduling information
* Memory-management information
* Accounting information
* File usage and I/O status information

__进程上下文__<br/>
The context of a process includes:

* the values of CPU registers
* the process state
* the program counter
* other memory/file management information

__上下文切换__<br/>
After the CPU scheduler selects a process (from the ready queue) and before allocates CPU to it, the CPU scheduler must:

* save the context of the currently running process into PCB
* put it into a queue
* load the PCB containing context of the selected process
* let it run

Context-switch time is overhead, the system does no useful work while switching. Time depend on hardware support

### Operations and APIs on Processes

__进程的创建__<br/>
The process creation forms a tree of processes.

* 资源共享：
  * 子进程共享父进程所有资源
  * 子进程只共享父进程资源的子集
  * 子进程不共享父进程的资源

* 执行：
  * 父进程子进程同时执行
  * 父进程等待子进程结束

* 地址空间

  * 子进程复制(duplicate)父进程的地址空间
  * 子进程用程序加载地址空间

* UNIX的例子：<br/>`fork`系统调用复制父进程的地址空间，`exec`系统调用在`fork`之后将子进程加载到地址空间中。<br/>
  在父进程中执行`int rc = fork();`后，由于同时创建了子进程，所以父进程和子进程中都执行了`fork`函数，因此，在此命令之后，所有代码执行两遍。父子进程执行顺序取决于进程调度器。<br/>
  此外，`fork`创建的子进程只包含一个线程，该线程为主进程中调用`fork`函数的线程。

__进程的结束__

* Process executes last statement and asks the operating system to delete it (`exit`).
  * Output  data from child to parent (via `wait`)
  * Process' resources are deallocated by OS.
* Parent may terminate execution of children processes (`abort`)
  * Child has exceeded allocated resources
  * Task assigned to child is no longer required
  * Parent is exiting
    * Operating system does not allow child to continue if its parent terminates
    * Cascading termination
* `wait` system call
  如果进程执行了`wait(NULL)`函数，那么其一定等待子进程结束以后再执行
* `exec` system call<br/>
  The process that is created by using the `exec()` system call can be a different program<br/>
  It does not create a new process; rather, it transforms the currently running program into a different running program

### Process Scheduling

__Process scheduling queues__

* Job queue<br/>
  set of all processes in the system
* Ready queue<br/>
  set of all processes residing in main memory, ready and waiting to execute
* Device queues<br/>
  set of processes waiting for an I/O device

__Scheduler(调度器)__

* Long-term scheduler (job scheduler)
  * selects which processes should be loaded into memory for execution.
  * Long-term scheduler is invoked very infrequently (seconds, minutes).
  * __The long-term scheduler controls the degree of multiprogramming.__
  * Long-term scheduling performs a gatekeeping function. It decides whether there's enough memory, or room, to allow new programs into the system.
  * Long-term scheduling affects processes new, exited.
* Short-term scheduler (CPU scheduler)
  * selects which process should be executed next and allocates CPU.
  * Short-term scheduler is invoked very frequently (milliseconds).
  * Short-term scheduling affects processes running; ready; blocked.

__CPU burst__<br/>
The period of computation between I/O requests is called the CPU burst.

进程按照占用时间可分为：

* I/O-bound process (I/O密集型进程)<br/>
  spends more time doing I/O than computations, many short CPU bursts.
* CPU-bound process (CPU密集型进程)<br/>
  spends more time doing computations, few very long CPU bursts.

### Interprocess Communication

__独立进程与协作进程__

* Independent process cannot affect or be affected by the execution of another process.
* Cooperating process can affect or be affected by the execution of another process.<br/>
  优点：
  * Information sharing
  * Computation speed-up
  * Modularity(模块化)<br/>
    一个进程崩溃不会导致别的进程崩溃
  * Convenience

__进程协作模式__

* Share memory模式<br/>
  producer process produces information that is consumed by a consumer process.

  * unbounded-buffer places no practical limit on the size of the buffer(一般在外存中实现)
  * bounded-buffer assumes that there is a fixed buffer size(一般在内存、Cache中实现)

  常用循环队列来实现缓冲区。

* Message-passing模式<br/>
  processes communicate with each other without resorting to shared variables.

__进程间通信__<br/>
进程间交流并同步行为的机制

* 直接通信
* 间接通信

## Chapter 4 Threads

__线程__

* 线程也被叫做轻量级进程(LWP)，是CPU执行的基本单元。
* 线程包含
  * 线程ID
  * 程序计数器
  * 寄存器集
  * 栈
* 与进程不同的是，一个线程与其他线程共享同一个代码段、数据段及其他操作系统资源（如：文件和信号）
* 如果数据段中的一个指针指向堆空间的地址，则该指针由所有线程共享；如果栈中的一个指针指向堆空间的地址，则该指针由线程私有。
* 一个进程在被创造出来之后由一个单一线程来控制，称为主线程。当主线程结束后，该进程的所有线程都被关闭。

__线程的应用__

* MVC模式中，model, view和controller各占一个线程
* 多线程网络服务器，包含调度者线程和工作者线程（一种事件驱动型框架）

__线程的好处__

* 响应性
* 资源共享
* 经济
* 利用CPU的多处理器架构

__用户线程与内核线程__

* 用户线程
  * 线程的管理由用户层的线程库完成
  * 例子：
    * POSIX中的Pthreads
    * Mach中的C-threads
    * Solaris中的UI-threads
  * 用户线程由用户层支持。内核并不干涉用户线程，从而用户线程更高效
  * 所有线程的创造、结束、合并、调度的都由一个库提供
  * 如果线程被阻塞，该进程的所有线程同样被阻塞
  * 现代操作系统中的用户线程大都被淘汰了
* 内核线程
  * 由内核支持。内核在内核空间中进行线程创建、结束、结合和调度
  * 内核线程通常比用户线程慢
  * 一个线程的阻塞并不会导致该进程的其他线程阻塞
  * 在多处理器环境中，内核可以在不同的处理器上调度线程

__多线程模型__

* Many-to-One<br/>
  多个用户线程对应一个内核线程。<br/>
  常用于不支持内核线程的系统
* One-to-One<br/>
  每一个用户线程对应一个内核线程
* Many-to-Many<br/>
  多个用户线程对应多个内核线程<br/>
  允许操作系统创建充分多的内核线程<br />
  需要考虑__调度器的激活__
  * 多对多模型需要通信来维护恰当数量的内核线程
  * 调度器的激活提供了upcall用于内核与线程库的通信
  * 这种通信允许一个应用维护恰当数量的内核线程

__Pthreads__<br/>
是一个POSIX标准API，用于线程创建和同步

线程的创建：

```C
/**
 @param tid handle or ID of created thread
 @param attr attributes of thread to be created, specify NULL to use default attributes
 @param function function to be mapped to thread
 @param arg single argument to function, if no argument to function, specify NULL
 
 @return integer return value for error code. 
 		EAGAIN - insufficient resources to create thread; 
 		EINVAL - invalid attribute
 */
int pthread_create(pthread_t *tid, const pthread_arrt_t *attr, void *(*function)(void*), void *arg);
```

在执行`pthread_create`之后，理论上讲，主线程、新建的线程的调用顺序是随机的，但是多数情况下只执行主线程。

线程一经创建就开始执行函数`function`, 函数执行过程中的任何两行__汇编代码__之间都可能会和其他线程之间进行切换。切换过程中只保存当前线程的寄存器值。因此会导致__不可控调度__.

__线程状态__

* 可结合的(joinable)<br/>
  线程默认都是可结合的状态.<br/>
  直到`pthread_join`被调用, 资源都一直被保留
* 分离的(detached)<br/>
  分离的线程不可以被结合<br/>
  资源可以在结束时被回收。

__等待线程__

```C
/**
 @param tid handle of joinable thread
 @param val_ptr exit value returned by joined thread. If no return value expected, use NULL
 
 @return integer return value for error code.
 		ESRCH - thread not found
 		EINVAL - thread not joinable
 */
int pthread_join(pthread_t *tid, void **val_ptr);
```

`pthread_join`让线程等待句柄为`tid`的线程结束。<br/>
只有一个线程可以被结合<br/>
线程必须是可结合的状态

__不可控调度__

* 竞争条件<br />指的是多个进程或线程并发地获取并操作同一个数据，并且执行结果依赖于这些线程或进程的执行顺序。这将导致不确定性。
* 关键代码段<br />
  多个线程执行的同一个代码段，这将导致一个竞争条件

一个线程去访问另一个线程栈上的地址是不安全的，因为另一个线程栈上的当前地址可能已被弹出，会导致dangling pointer.

__线程的结束(Cancellation)__

* 指的是在一个线程结束(finished)之前将其终结(terminate)

* 两种方法：

  * 异步结束<br/>
    立刻终结目标线程。<br/>
    如果目标线程拥有一些系统级的资源，那么系统将不能够回收所有资源。可能导致__内存泄漏__(Memory leakage).
  * 延迟结束<br/>
    允许目标线程重复确定其是否可以被结束。<br/>目标线程自己决定何时结束。因此可以回收资源。

* 大部分系统都实现了进程和线程的异步结束（使用`kill`系统调用），pthread实现了延迟结束。

__Signal handling__

* Signals在UNIX系统中用来告诉线程某个特定事件发生了
* 所有Signal都遵循相同的模式：
  * Signal被特定事件产生
  * Signal被发送给一个线程
  * Signal被处理

__线程池__

* 在一个池(pool)中创建一些线程，这些线程都等待工作。
* 优点：
  * 通常处理一个已经存在的线程比创建一个新线程快
  * 可以控制应用中的线程的内存空间大小

__特定于线程的数据(Thread specific data)__

* 允许每个线程拥有自己的一份数据的拷贝
* 当你没有线程创建权限的时候十分有用（如使用线程池时）

## Chapter 5 CPU Scheduling

本章提到的进程包括轻量级进程（线程）和重量级进程。

CPU调度的基本单元为进程。

CPU调度的目标为最大化CPU的利用率。方法为在一个进程进入I/O burst时，让另一个进程使用CPU.

__CPU-I/O burst循环__<br />进程的执行包括CPU执行和I/O等待的循环

__CPU调度器__

* CPU调度器从准备队列中选择进程，并分配CPU给它
* 准备队列并不遵循先进先出。是优先权队列(Priority queue), 以堆来实现。

__应发生CPU调度的情况__

* 进程从running态切换到wait态（如I/O）
* 进程从running态切换到ready态（如中断发生）
* 进程从wait态切换到ready态（如I/O完成）
* 进程结束

__抢占式(Preemptive)或非抢占式__

* 非抢占式调度<br />当进程主动进入waiting态或结束时的调度。<br />简单，但不高效
* 抢占式调度<br />在所有可能的情况下都会发生调度。<br />由于在调度的时候有可能内核正在关键代码段处理重要数据，因此内核需要特别注意这种情况，因此更为复杂。

__分配器(Dispatcher)__

* 分配器将CPU的控制权交给由CPU调度器选择的进程。这包括：
  * 执行上下文切换（保存、加载）
  * 切换到用户态
  * 跳到用户程序特定的位置以重启程序
* 分配的延迟成本<br />分配器停止进程并启动另一个进程的时间

__调度的策略与机制__

* 调度的策略包括使用哪个进程、以何种顺序、运行多长时间等
* 调度的机制包括如何实现调度的策略

__调度的准则__

* CPU利用率
* 吞吐量(Throughput)<br />单位时间内完成的进程数
* 周转时间(Turnaround Time)<br />一个进程从提交到完成的时间，包括：
  * 在进入系统之前的等待时间（由Long-time scheduler控制）
  * 在准备队列中的等待时间（由Short-time scheduler控制）
  * 在其他事件中的等待时间（如I/O）
  * 在CPU中实际运行的时间
* 等待时间<br />进程在准备队列中等待时间的总和
* 响应时间<br />从请求的提交到第一次开始响应的时间。不包括输出响应的时间。

__调度的算法__

* 先到先服务模型(FCFS)<br />第一个向CPU提出请求的进程被分配给CPU<br />常用队列实现。<br />非抢占式。该进程将一直占用CPU直到进程结束或者主动进入wait态。<br />常会导致__舰队效应__，即短进程等待长进程。

* Round Robin<br />每个进程被分配一个时间片。<br />所有的进程在准备队列中先进先出。<br />当CPU闲置的时候，调度器将准备序列中的第一个进程分配给CPU并且让它在一个时间片内运行<br />如果一个进程使用CPU的时间小于一个时间片，那么它将被移动到队列的尾部。<br />如果一个进程使用CPU的时间多于一个时间片，那么当一个时间片的时间用完了，该进程将被调度器抢占并且移动到队列的尾部。<br />如果一个时间片长于所有的CPU burst时间，那么该算法就变成了FCFS；如果一个时间片短于所有的CPU burst时间，那么该算法就变成了进程共享。一般来说，80%的CPU burst的时间应该短于时间片长度。<br />上下文切换会影响该算法的性能。<br />周转时间依赖于时间片的长度。<br />响应时间：对于$m$个进程，最坏情况下的响应时间为$O(m)$<br />优点：公平。响应时间较短。<br />缺点：平均周转时间较长。

* 彩票调度(Lottery scheduling)<br />彩票调度器是一种按比例分配的调度器。其试图保证每个进程获得一定比例的CPU时间。<br />基本思想：调度器拥有一个彩票(Lottery)来决定下一个运行的进程。应该被运行更多次的进程有更大的机会赢得彩票。票(Ticket)用来表示一个进程获得的资源。<br />由于票的赋予是个困难的问题，所以该模式并不普遍。

* 最短工作优先调度(SJF)<br />依据进程下一个CPU burst的长度来调度进程，选择时间最短的。<br />常用优先级队列实现。<br />SJF可以分为抢占式和非抢占式。

  * 抢占式<br />如果一个新进程进入准备队列，且其CPU burst的长度小于当前执行的进程的剩余时间，则抢占。
  * 非抢占式<br />一旦CPU被分配给某个进程，那么直到该CPU burst完成之前不能被抢占。

  SJF是最好的，其平均等待时间在单核情况下是（可证明的）最小的。但有可能导致有些进程永远无法执行（称为starvation）。<br />SJF要求知道进程的下一次CPU burst的时间。但是这通常是不知道的，被称作non-clairvoyant. 可以利用指数平均公式(exponential averaging)来估计下一次CPU burst的时间：

  1. 设$t_n$为第$n$次CPU burst的实际长度
  2. 设$\tau_{n}$为预测的第$n$次CPU burst的长度
  3. 给定$\alpha$满足$0\leq\alpha\leq 1$
  4. 定义$\tau_{n+1}=\alpha t_n+(1-\alpha)\tau_n$

* 优先级调度<br />每个进程都有一个优先级。<br />优先级可以内部决定或者外部决定：

  * 内部优先级<br />由时间限制、内存需求、文件哈希等决定
  * 外部优先级<br />并不由操作系统控制（如进程的重要性）

  调度器总是选择准备序列中优先级最高的进程运行<br />FCFS和SJF都是优先级调度的特殊形式。<br />优先级调度可以是非抢占式或抢占式的。

  * 抢占式优先级调度<br />如果新到达的进程的优先级比当前运行的进程高，则当前运行的进程被抢占
  * 非抢占式优先级调度<br />如果新到达的进程的优先级比当前运行的进程高，当前运行的进程结束后转给新到达的进程。

  可能出现低优先级的进程永远不会被运行。（出现starvation）解决方法：Aging.<br />__Aging__<br />如果一个进程在系统中等待了过长时间，则会逐渐提升该进程的优先级

|      | Average Turnaround Time | Response Time      | Fairness |
| ---- | ----------------------- | ------------------ | -------- |
| FCFS | Bad, convoy effect      | Bad, convoy effect | Bad      |
| Round Robin | Bad, change with time quantum | Good | Good |
| Lottery | Bad, any policy that seeks fairness is bad on performance | Probabilistic, so no guarantee on the worst case | Better and more flexible, but ticket assignment is hard |
| SJF | Provably optimal | Bad | Bad, essentially a priority scheduler that favors short jobs |
| Priority Scheduling | Could be good, if higher priority is given to processes with shorter CPU bursts | Bad, a low-priority process may not be executed after a long time | Bad, have starvation problem, can be mitigated by aging |

__Multilevel Queue__

* 准备队列被分为分离的队列
  * 前台（交互的）
  * 后台（批处理的）
* 每个进程根据进程的某些性质（如内存使用、优先级、进程类型等）被永久分给一个队列。
* 每个队列有自己的调度算法
  * 前台：RR
  * 后台：FCFS
* 一个进程可以运行当且仅当在这个进程所处队列之上的所有队列为空
* 当一个进程正在运行，而另一个在更高优先级队列中的进程进入，则当前运行的进程被抢占
* 调度是在队列之间使用的
  * 固定优先级调度（即先服务前台在服务后台），可能会导致starvation
  * 彩票调度
* __Multilevel feedback queue__<br />允许进程在进程之间迁移（可以使用Aging）。<br />如果一个进程使用了更多的CPU时间，它将迁移到更低优先级的队列中。因此，I/O密集型进程将处于高优先级队列。<br />由以下参数定义：
  * 队列个数
  * 每个队列的调度算法
  * 何时升级进程
  * 何时降级进程
  * 当需要服务时，进程进入哪个队列

__Linux调度__

* time-sharing
  * 由信用度来决定优先级
  * 当计时器中断出现时，信用度减少
  * 当信用度为0时，另一个进程被选择
  * 当所有可运行的进程都有0信用度，则重新分配信用度
* real-time<br />每个CPU都有一个运行队列，由140个使用FIFO顺序的优先级队列组成。

## Chapter 6 Process Synchronization

三种实现进程同步的机制：

* 互斥锁(exclusive lock)
* 共享锁(shared lock)
* 其他进程同步机制，如障碍(barrier)

互斥锁的POSIX API:

* `int pthread_mutex_lock(pthread_mutex_t *mutex)`
* `int pthread_mutex_unlock(pthread_mutex_t *mutex)`

关键代码段协议<br />一个关键代码段协议包含两个部分：入口段（或锁）以及出口段（或解锁）。在这两个段之间的是必须以互斥方式运行的关键代码段。

__互斥__

* 如果一个进程正在执行它的关键代码段，那么其他进程都不能执行它们的关键代码段。
* 入口协议应阻塞其他想要进入但不能进入的进程
* 当进程结束执行关键代码段，入口协议应当被通知同时允许一个等待进程进入。

__Progress__

* 如果没有进程正在执行关键代码段，并且有一些进程希望进入它们的关键代码段，接着
  * 只有想要进入关键代码段的进程可以参加竞争
  * 其他进程无法影响这个决策
  * 这个决策不能被无限推迟

__Bounded waiting__

* 在一个进程提出进入关键代码段的请求后，在其被允许进入之前，存在一个上界，使得至多个数个进程被允许进入
* 为了防止starvation

互斥锁应该通过如下测试用例：

* 一个进程不断尝试进入关键代码段<br />测试的是进程重复进入关键代码段是否独立于别的进程的尝试
* 一个进程已经处于关键代码段，同时其他进程尝试进入<br />测试的是安全锁
* 两个进程尝试同时进入关键代码段<br />测试的是是否可能两个进程互相锁住对方的进入，以及是否可能两个同时进入。

用户态实现互斥锁方法一：

```C
bool lock;//initially lock = false;
do {
  while (lock);
  lock = true;
  //critical section
  lock = false;
  //remainder section
} while (1);
```

无法解决两个进程同时进入关键代码段的问题。

用户态实现互斥锁方法二：

```C
int victim;//initially victim = i; (or victim = j;) 
do {
  victim = i;//for process Pi
  while (victim == i);//for process Pi
  //critical section
  //do nothing for CS exit
  //remainder section
} while (1);
```

无法解决只有一个进程想进关键代码段

用户态实现互斥锁方法三：

```C
bool flag[2];//initially flag[0] = flag[1] = false;
do {
  flag[i] = true;//for process Pi
  while (flag[j]);//for process Pi
  //critical section
  flag[i] = false;
  //remainder section
} while (1);
```

无法解决两个进程同时进入关键代码段

__Peterson算法__

```C
bool flag[2];//initially flag[0] = flag[1] = false;
int victim;//initially victim = i; (or victim = j;) 
do {
  flag[i] = true;//for process Pi
  victim = i;//for process Pi
 	while (flag[j] && victim == i);//for process Pi
  //critical section
  flag[i] = false;
  //remainder section
} while (1);
```

__Lamport面包店算法__

* 在进入关键代码段之前，进程收到一个数字。拥有最小数字的进程进入关键代码段。

* 对于收到相同数字的进程$P_i$和$P_j$, 如果$i<j$,, 则先服务$P_i$; 否则先服务$P_j$.

* 产生数字的方法总是产生递增的数字，如：1, 2, 3, 3, 3, 4, 5, ...

* 记号：`(a, b) < (c, d)`当且仅当`a < c`或`a = c`且`b < d`

* ```C
  bool choosing[n];//initially choosing[0] = choosing[1] = ... = false;
  int number[n];//initially number[0] = number[1] = ... = 0;
  
  do {
    choosing[i] = true;
    number[i] = max(number[0], number[1], ..., number[n - 1]) + 1;
    choosing[i] = false;
    for (int j = 0; j < n; j++)
    {
      while (choosing[j]);
      while ((number[j] != 0) && ((number[j], j) < (number[i], i)));
  	}
    //critical section
    number[i] = 0;
    //remainder section
  } while (1);
  ```

__进程同步的硬件支持__

* 关中断/开中断<br />在多核系统上慢并且难以实现

* 特殊机器指令

  * Test and set<br />Test and modify the content of a machine word atomically.<br />即一个指令中同时读写内存

    ```C
    bool lock = false;
    
    bool TestAndSet(bool &target)
    {
      bool rv = target;
      target = true;
      return rv;
    }
    
    do {
      while (TestAndSet(lock));
      //critical section
      lock = false;
      //remainder section
    } while (1);
    ```

    不满足bounded waiting.<br />改进：

    ```C
    //shared data
    bool lock = false;
    bool waiting[n];
    
    //local variable
    book key;
    
    do {
      waiting[i] = true;
      key = true;
      while (waiting[i] && key)
        key = TestAndSet(lock);
      waiting[i] = false;
      //critial section
      j = (i + 1) % n;
      while ((j != i) && !waiting[i])
        j = (j + 1) % n;
      if (j == i)
        lock = false;
      else
        waiting[j] = false;
      //remainder section
    } while (1);
    ```

    

  * Swap<br />Atomically swap two variables.

  __DPDK lockless ring buffer__<br />The buffer enqueue and dequeue operations are implemented by using an atomic Compare-And-Swap instruction.

  __semaphore(信号量)__

  * 是一个同步工具，需要内核的支持。

  * semaphore = counter + kernel mutex(防止counter的自增、自减操作重叠) + waiting list

  * 是一个整型变量，只可以通过两个原子操作`wait`和`signal`的访问。

    ```pseudocode
    wait(S):
    while S <= 0 do no-op;
    S--;
    
    siginal(S):
    S++;
    ```

  __Semaphore的实现__

  ```C
  typedef struct {
    int counter;
    struct process *L;
    //an in-kernel exclusive lock;
  } semaphore;
  
  //block: block the process that invokes it.
  //wakeup(P): resumes the executions of an blocked process P.
  
  //implementation (1)
  wait(S):
  //Disable interrupts;
  S.counter--;
  if (S.counter < 0) {
    //add this process to S.L;
    block;
  }
  //Enable interrupts;
  
  signal(S):
  //Disable interrupts;
  S.counter++;
  if (S.counter <= 0) {
    //remove a process P from S.L;
    wakeup(P);
  }
  //Enable interrupts
  
  //implementation (2)
  wait(S):
  while (TAS(S.lock));
  S.value--;
  if (S.value < 0) {
    //add this process to S.L;
    block;
  }
  lock = 0;
  
  signal(S):
  while (TAS(S.lock));
  S.value++;
  if (S.value <= 0) {
    //remove a process P from S.L;
    wakeup(P);
  }
  lock = 0;
  ```

  

__POSIX 中的semaphore__

* 位于头文件`semaphore.h`
* 定义一个semaphore，使用语句`sem_t sem_name;`或`sem_t *sem_pointer;`
* 初始化semaphore使用`int sem_init(sem)t *sem, int pshared, unsigned int initial_value);`或`sem_t *sem_open(const char *name, int oflag, unsigned int initial value);`
* `int sem_wait(sem)t *sem_pointer`和`int sem_post(sem_t *sem_pointer)`

__semaphore的应用__

* Act as an event notification tool.<br />Execute B in Pj only after A executed in Pi:<br />
  在Pi中执行A之后执行`signal(flag)`, 然后在Pj中B之前执行`wait(flag)`

* 解决关键代码段问题

  ```C
  semaphore lock;//initiall lock = 1;
  
  do {
    wait(lock);
    //critical section
    signal(lock);
    //remainder section
  } while (1);
  ```

  

__semaphore的副作用：死锁和Starvation__

__用semaphore解决同步的经典问题__

* Bounded-Buffer Problem (or called Producer-Consumer Problem)

  * Solution 1

    ```C 
    semaphore fillCount, emptyCount;//initially fillCount = 0, emptyCount = n
    //fillCount: the number of items in the buffer
    //emptyCount: the number of empty slots in the buffer
    
    //Producer:
    do {
      //produce an item in nextp
      
      wait(emptyCount);
      //add nextp to buffer
      signal(fillCount);
    } while (1);
    
    //Consumer:
    do {
      wait(fillCount);
      //remove an item from buffer to nextc
      signal(emptyCount);
      //consume the item in nextc
    } while (1);
    ```

    此代码不行，因为在读写`buffer.counter`时会导致竞争条件

  * Solution 2

    ```C
    semaphore fillCount, emptyCount, mutex;//initially fillCount = 0, emptyCount = n, mutex = 1
    //mutex: guarantee the mutual exclusive access of the shared buffer
    
    //Producer:
    do {
      //produce an item in nextp
      
      wait(mutex);
      wait(emptyCount);
      //add nextp to buffer
      signal(fillCount);
      signal(mutex);
    } while (1);
    
    //Consumer:
    do {
      wait(mutex);
      wait(fillCount);
      //remove an item from buffer to nextc
      signal(emptyCount);
      signal(mutex);
      //consume the item in nextc
    } while (1);
    ```

    会导致死锁(Producer在`wait(mutex)`, Consumer在`wait(fillCount)`)。

  * Solution 3

    ```C
    semaphore fillCount, emptyCount, mutex;//initially fillCount = 0, emptyCount = n, mutex = 1
    //mutex: guarantee the mutual exclusive access of the shared buffer
    
    //Producer:
    do {
      //produce an item in nextp
      
      wait(emptyCount);
      wait(mutex);
      //add nextp to buffer
      signal(mutex);
      signal(fillCount);
    } while (1);
    
    //Consumer:
    do {
      wait(fillCount);
      wait(mutex);
      //remove an item from buffer to nextc
      signal(mutex);
      signal(emptyCount);
      //consume the item in nextc
    } while (1);
    ```

  * Summary

    * 需要用`mutex`信号量来确保对关键共享资源的互斥访问
    * 信号量`wait`的顺序很重要，要将`wait(mutex)`尽可能接近对关键共享资源的访问
    * 信号量`signal`的顺序不重要
    * 不建议将produce an item和consume an item放到`wait(mutex)`和`signal(mutex)`之间，会降低程序性能
    * 如果buffer的size为1，可以去掉`mutex`

* Readers and Writers Problem (or called shared-lock problem)<br />Writer只能在没有Reader时进行写操作

  * Solution 1

    ```C
    semaphore mutex, wrt;//initiallly mutex = 1, wrt = 1
    int readCount;//the number of readers browsing the shared content. initially readCount = 0.
    //mutex: guarantee the mutual exclusive access to the readCount variable
    //wrt: the right of modifyng the shared content
    
    //Writer Process:
    wait(wrt);
    //writing is performed
    signal(wrt);
    
    //Reader Process:
    wait(mutex);
    readCount++;
    signal(mutex);
    if (readCount == 1)
      wait(wrt);
    //reading is performed
    wait(mutex);
    readCount--;
    signal(mutex);
    if (readCount == 0)
      signal(wrt);
    ```

    不正确，如果之前没有Reader，在有两个Reader同时进行读操作时，在判断`readCount==1`前`readCount`自增了两次。

  * Solution 2

    ```C
    //Writer Process
    wait(wrt);
    //writing is performed
    signal(wrt);
    
    //Reader Process
    wait(mutex);
    readCount++;
    if (readCount == 1)
      wait(wrt);
    signal(mutex);
    //reading is performed
    wait(mutex);
    readCount--;
    if (readCount == 0)
      signal(wrt);
    signal(mutex);
    ```

* Dining-Philosophers Problem

  ```C
  semaphore chopstick[5];//initial valus of all semaphores are set to 1
  
  //Philosopher i
  do {
    wait(chopstick[i]);
    wait(chopstick[(i + 1) % 5]);
    //eat
    signal(chopstick[i]);
    signal(chopstick[(i + 1) % 5]);
    //think
  } while (1);
  ```

  会产生死锁、Starvation和不公平

__条件变量__

* 条件变量机制允许线程暂停执行并且放弃处理器，直到某些条件被达到。
* 信号量的问题：无法读取在信号量中存储的计数器
* 一个条件变量必须在一个mutex之中使用，以防发生竞争条件：一个进程准备等待，同时另一个进程在该进程实际等待之前signal了一个条件。
* 条件变量的`wait()`总是会阻塞它的调用者
* 条件变量的`signal()`要么是放一个进程，要么什么都不做
* 如果`signal()`是放一个进程，要么调用者，要么被释放的进程会继续，但不会同时继续。
* 在使用条件变量时，尽量用`while`来判断条件变量是否满足某个条件。

__障碍物的同步问题__

* 假设需要进行一个多线程的计算。该计算拥有两个状态，但是我们不希望第二个状态在第一个状态完成之前执行。

* 我们可以使用一个同步方法称为障碍物。当一个线程遇到障碍物，它会等待知道所有的线程都达到那个障碍物，然后一起继续。

* Pthreads中可以用`pthread_barrier_wait()`函数实现此功能。

* 用条件变量实现：

  ```C
  #define N (16)
  double data[256][8192];
  pthread_mutex_t m;
  pthread_cond_t cv;
  
  int main()
  {
  	int tids[N], i;
    pthread_mutex_init(&m, NULL);
    pthread_cond_init(&cv, NULL);
    for (i = 0; i < N; i++)
    {
      tids[i] = i;
      pthread_create(&ids[i], NULL, calc, &(tids[i]));
  	}
    for (i = 0; i < N; i++)
      pthread_join(ids[i], NULL);
  }
  
  double data[256][8192];
  int remain = N;
  void *calc(void *ptr)
  {
    pthread_mutex_lock(&m);
    remain--;
    if (remain == 0)
      pthread_cond_broadcast(&cv);
    else
    {
      while (remain != 0)
        pthread_cond_wait(&cv, &m);
    }
  }
  ```

  

__管程(Monitor)__

* 一种高级同步结构，允许一个抽象数据类型在并发的进程之间安全地共享。

  ```C
  monitor monitor-name
  {
  	//shared variable declarations
  	procedure body P1(...) {
  	...
  	}
  	procedure body P2(...) {
  	...
  	}
  	procedure body Pn(...) {
  	...
  	}
  	{
  		//initialization code
  	}
  }
  ```

* 在一个管程内之多只能执行一个进程

* 当进程调用了管程的一个`procedure`并且成功进入管程，那么它就是管程内唯一执行的进程

* 当进程调用了管程的一个`procedure`并且管程内已经有一个进程在执行，那么调用者会在管程外被阻塞

* 管程具有事件通知的属性：

  * 为了允许一个进程在管程外等待，需要声明条件变量：

    ```C
    condition x, y;
    ```

  * 条件变量只能使用`wait`和`signal`两个操作

* 在一个进程（称为signaling process）内，对一个条件变量使用`signal`唤醒了另一个进程（称为released process）, 那么这两个进程是存在竞争的。有两种解决方法：

  * released process接管管程并且signaling process在管程外等待
  * released process在管程外等待并且signaling process接管管程

* 利用管程解决Producer-Consumer问题

  ```C
  monitor PCbuffer {
    int itemCount; //BUFSIZE
    condition full, empty;
    putItemIntoBuffer(item) {...}
    Item removeItemFromBuffer() {...}
    
    procedure void add(item) {
      while (itemCount == BUFSIZE)
        full.wait(); 
      putItemIntoBuffer(item);
      itemCount = itemCount + 1;
      if (itemCount == 1)
        empty.signal();
      return;
    }
    
    procedure item remove() {
      while (itemCount == 0)
        empty.wait();
      item = removeItemFromBuffer();
      itemCount = itemCount - 1;
      if (itemCount == BUFSIZE - 1)
        full.signal();
      return item;
    }
  }
  
  procedure producer() {
    do {
      item = produceItem();
      PCbuffer.add(item);
    } while (true);
  }
  
  procedure consumer() {
    do {
      item = PCbuffer.remove();
      consumeItem(item);
    } while (true);
  }
  ```

* 利用管程解决Dining Philosophers问题

  ```C
  monitor dp {
  	enum {
      thinking, hungry, eating
    } state[5];
    condition self[5];
    
    procedure void pickup(int i) {
      state[i] = hungry;
      test(i);
      while(state[i] != eating)
        self[i].wait();
    }
    
    procedure void putdown(int i) {
      state[i] = thinking;
      test((i + 4) % 5);
      test((i + 1) % 5);
    }
    
    procedure void test(int i) {
      if ((state[(i + 4) % 5] != eating) && (state[i] == hungry) && (state[(i + 1) % 5] != eating)) {
        state[i] = eating;
        self[i].signal();
      }
    }
    
    {
      for (int i = 0; i < 5; i++)
        state[i] = thinking;
    }
  }
  ```

  

## Chapter 7 DeadLocks

__deadlock__<br />一些阻塞的进程每个都拥有一个资源，并且等待获得对方拥有的资源

__System model__

* Resource types: $R_1, R_2, \ldots, R_m$
* 每个资源类型$R_i$拥有$W_i$个对象
* 每个进程对一个资源有以下操作：
  * Request<br />如果一个进程对一个不能立刻给予的系统资源提出了请求，那么该进程必须被阻塞直到它获得资源
  * Use<br />进程可以操作资源
  * Release<br />进程释放资源
* 死锁<br />一些进程处于死锁状态当且仅当每个进程都在等待一个只能被对方触发的事件

__死锁的必要条件__

* Mutual exclusion<br />同时只能有一个进程可以use资源
* Hold and wait<br />一个进程必须拥有一个资源，并且等待另一个
* No preemption<br />只有当拥有该资源的进程在完成它的任务后主动release该资源，该资源才能被release
* Circular wait<br />A waits for B, B waits for C, C waits for A.

__检验死锁的方法__

* 如果一个资源分配图中没有圈，则没有死锁
* 如果一个资源分配图中有圈：
  * 如果每个资源类型只有一个对象，那么有死锁
  * 如果每个资源类型有多个对象，那么可能有死锁

__死锁预防__

* Mutual Exclusion

* Hold and wait<br />严格禁止一个进程拥有某些资源的时候去申请别的资源。<br />有两种可能的策略：

  * 一个进程必须在它运行之前获得所有资源
  * 当一个进程申请资源时，它必须不拥有资源

  资源利用率较低，也可能导致Starvation

* No preemption<br />如果一个拥有某些资源的进程请求了别的不能立刻分配给它的资源，那么所有当前被占有的资源都会被release<br />如果请求的资源不能获得：

  * 如果他们被正在等待新资源的进程占有，那么这些资源被抢占并分配给需要它的进程
  * 否则，申请该资源的进程等待，直到资源可以获得。当它等待的时候，它拥有的资源可以被抢占

* Circular Wait<br />对所有资源类型进行排序。一个进程只能申请位置高于自己拥有的资源的资源。

* 用死锁预防来解决Dining-philosopher问题

  ```C
  semaphore chopstick[5] = {1, 1, 1, 1, 1};
  
  void philosopher(int i)
  {
    do
    {
      think();
      if (i % 2 == 0)
      {
        wait(chopstick[(i + 1) % 5]);
        wait(chopstick[i]);
        eat();
        signal(chopstick[(i + 1) % 5]);
        signal(chopstick[i]);
      }
      else
      {
        wait(chopstick[i]);
        wait(chopstick[(i + 1) % 5]);
        eat();
        signal(chopstick[i]);
        signal(chopstick[(i + 1) % 5]);
      }
    } while (1);
  }
  ```


__死锁避免__

* 最简单有用的模型需要每个进程声明其需要的每个类型资源的最大数量
* 死锁避免算法动态检查资源分配状态赖保证没有环状等待条件
* 资源分配状态由可获得的被分配的资源数量，和进程的最大需求定义

__安全状态__

* 当一个进程需要一个可获得的资源，系统必须决定如果立刻分配资源，是否会让系统处于安全状态
* 系统处于安全状态当且仅当存在一个所有进程的安全序列运行到最后
* 进程序列是安全的当且仅当对于其中的每个资源$P_i$, 其仍可以需求的资源可以被当前可获得的资源+所有$P_j(j<i)$拥有的资源满足
  * 如果$P_i$的资源需求并不是可以立即获得的，那么$P_i$可以等待所有$P_j$结束
  * 当$P_j$结束，$P_i$可以获得需要的资源，执行，返回分配的资源，并且结束
  * 当$P_i$结束，$P_{i+1}$可以获得其需要的资源
* 如果一个系统处于安全状态，必然不存在死锁；如果一个系统处于不安全状态，可能会有死锁
* 避免方法：保证系统永远不会进入不安全状态

__银行家算法__

* 三个假设
  * 每个进程都实现声明其需要的每种资源类型的最大数量
  * 当一个进程需要一些特定数量的资源，它可能需要等待，即使系统有可用的资源
  * 当进程获得其所有需要的资源，它必须在有限时间内返还
* $n$: 进程数; $m$: 资源种类数
* `Available`<br />长度为$m$的向量，代表每种类型拥有的对象数量
* `Max`<br />$n\times m$型矩阵。代表进程最多需要的某个类型的对象数
* `Allocation`<br />$n\times m$型矩阵，代表进程当前被分配的资源对象数
* `Need`<br />$n\times m$型矩阵，代表进程还需要的资源对象数

__死锁检测__

* 每种资源类型只有一个对象

  * 维护一个wait-for图：
    * 每个结点是进程
    * 如果$P_i$等待$P_j$, 那么$P_i\to P_j$
  * 周期性调用死锁检测算法寻找图中的圈

  该算法复杂度为$O(n^2)$

* 每种资源类型有多个对象

  * `Available`<br />一个长度为$m$的向量代表每个类型可获得资源数量

  * `Allocation`<br />一个$n\times m$矩阵定义了每个类型当前分配给每个进程的资源数量

  * `Request`<br />一个$n\times m$矩阵代表当前每个进程的需求。

  * 算法：

    1. 让`Work`和`Finish`分别为长度为$m$和$n$的向量，其中

       * `Work = Available`
       * 对于$i = 1, 2,\ldots, n$, 如果`Allocation != 0`, 那么`Finish[i] = false`; 否则`Finish[i] = true`.

    2. 找到一个指标$i$, 使得

       * `Finish[i] == false`
       * `Request_i <= Work`

       如果不存在这样的$i$, 转步骤4

    3. `Finish[i] = true`<br />`Work = Work + Allocation_i`<br />转步骤2

    4. 如果存在$i$使得$Finish[i] == false$, 那么系统处于死锁。且$P_i$处于死锁

    该算法复杂度为$O(m\times n^2)$

* 死锁检测算法的用法

  * 何时，多么频繁地调用取决于：
    * 一个死锁多么频繁地会发生
    * 当死锁发生的时候，有多少进程会被影响

__死锁恢复__

* 终止所有死锁的进程
* 每次终止一个进程，直到死锁圈被消除
* 以何种顺序终止进程
  * 进程的优先级
  * 进程已经执行的时间，进程还需执行的时间
  * 进程使用的资源
  * 进程需要的资源
  * 需要终止的进程的数量
  * 进程是互动的还是批量的
* 资源抢占
  * 选择一个最小损失的victim
  * 回滚：回到安全状态后，重启进程
  * 饥饿：相同的进程总是被选为victim, 包括在计算损失因子时回滚的数量

__总结__

* 死锁检测和死锁避免的资源消耗都是昂贵的
* 必须评价死锁的消耗和频率与检测或避免的消耗
* 死锁避免和恢复可能会导致无限等待
* Unix, Windows使用Ostrich算法
* 典型的应用使用死锁预防
* 数据库需要大量使用死锁检测、恢复、避免、预防。

# Part Three Memory Management

## Chapter 8 Main Memory

__指令和数据与物理内存地址之间的连接__

* 编译时<br />如果一个程序运行时的内存地址事先已经知道，绝对地址可以直接由编译器生成。如果地址的起始地址改变了，那么需要重新编译
* 加载时<br />如果在编译时不知道内存地址，那么必须生成可重新确定位置的代码
* 执行时<br />如果进程在执行时可以从一个内存段移动到另一个，那么连接就需要被推迟到执行时。需要硬件支持。

__逻辑地址空间与物理地址空间__

* 逻辑地址空间的概念是正确内存管理的核心
  * 逻辑地址<br />由CPU生成，也被称为虚拟地址
  * 物理地址<br />内存单元的地址

__内存管理单元(MMU)__

* 将虚拟地址映射到物理地址的硬件设备
* 用户程序只需要处理逻辑地址，永远不会遇到物理地址
* 其接收CPU产生的逻辑地址，首先判断其小于等于limit(否则报错)，然后将其加上relocation register就成了物理地址

__Swapping__

* 一个进程可以被暂时从主存交换到一个后备仓库中，然后被重新回到主存来进一步执行
* 后备仓库<br />充分大的快速磁盘，足以存储所有用户的所有内存映像的拷贝。必须提供对内存映像的直接访问
* 换入，换出<br />低优先级的进程可以被换出，以让高优先级的进程载入并执行
* 交换时间的主要部分是传递时间。

__连续分配法__

* 固定分区
  * 主存被分为多个分区
  * 分区可以在之后被替换
  * 每个分区有一个Job queue, 或者所有分区拥有一个Job queue
* 动态分区
  * 洞(Hole)<br />可用内存块；内存里面有许多不同大小的洞
  * 当进程到达时，被分配给一个足够大的洞
  * 操作系统维护的信息包括
    * 分配的分区
    * 空闲的分区(hole)
  * 动态分配问题<br />如何分配洞
    * 首次适配<br />第一个足够大的洞
    * 最佳适配<br />最小的足够大的洞
    * 最差适配<br />最大的洞
  * 内部碎片<br />被分配但未被使用的内存
  * 外部碎片<br />未被分配的内存
  * 外部碎片缩化
    * 将内存内容重新排列，让空闲内存区域在一个大的块内
    * 当且仅当程序重定位是动态的，并且在执行时完成
    * 执行昂贵
* 地址映射方式<br />procID + virtual address = physical address<br />优点：地址翻译速度快<br />缺点：外部碎片+内部碎片+无法共享内存块

__段式内存分配法__

* 逻辑地址由两个部分组成：段号+偏移
* 段表<br />每个表包含基址和limit
* STBR指向段表的地址，STLR表示一个程序用的段数
* 地址映射方式<br />procID + segmentID + offset = physical address<br />内存中存储段表，CPU中base register存储段表位置，limit register存储段表长度。<br />优点：可以实现段级别的内存共享<br />缺点：内部碎片+外部碎片

__页式内存分配法__

* 物理内存被分为许多称为帧(frame)的块；逻辑内存被分为许多称为页(page)的块
* 记录所有空闲的帧。为了运行一个$n$页的程序，需要找到$n$个空闲的帧并加载程序。建立一个页表来将逻辑地址映射为物理地址。
* 优点：无外部碎片<br />缺点：地址翻译慢
* 地址映射方式<br />逻辑地址被分为页号和页偏移。页号被用作页表中的索引，页偏移和基址地址一起来确定物理地址。<br />每次翻译需要两次访存，一次访问页表，一次访问地址

__高级页表结构__

* 层次化页表(Hierarchical Paging)<br />动机：一个单层次页表的大小可能会大于内存容量。<br />解决方法：将逻辑地址空间分为多个页表。<br />32位系统：42位outer pager + 10位inner page + 12位offset<br />64位系统：32位2nd outer page + 10位outer page + 10位inner page + 12位offset
* 哈希页表<br />动机：三层页表仍然过大。<br />解决方法：采用chained hash table
* 插入页表<br />动机：每个进程都需要维护一个页表<br />解决方法：每一个page entry包含页的虚拟地址，以及拥有该页的进程的信息。采用哈希表来限制搜索复杂度。

## Chapter 9 Virtual Memory

__思想__<br />实现了逻辑地址与物理地址的分离

* 只有部分程序需要在主存中保留以执行
* 逻辑地址空间因此可以比物理地址空间大
* 更多的程序可以同时运行
* 更少的I/O
* 实现方法
  * 按需调页
  * 按需调段

__按需调页__<br />只在一个页需要进入内存时才将其调入内存

* 需要更少I/O
* 需要更少内存
* 更快的响应
* 适用于更多用户

当一个页面被需要时，就去引用它：

* 非法引用：终止程序
* 不再内存中：调入内存

标志页引用是否有效的Bit位

* 在每个页表项内，需要一个标识位用来标志是否有效<br />1: 在内存中；0: 不再内存中
* 最初所有的页表项的该位都置0
* 在地址翻译过程中，如果该页表项的该位是0，则产生页错误

处理页错误的方法

* OS查看另一个表格来决定：
  * 非法引用：终止
  * 只是不在内存中
* 获得空的帧
* 将外存中的页换入刚刚获得的帧中
* 重设表格，该项的validation bit = 1
* 重新继续执行程序

__Copy-on-Write__

* COW允许父进程与子进程最初享有内存中相同的页，只有当某个进程修改了页，才会将该页copy
* 空闲页从一个zero-fill-on-demand的页池中分配

`vfork()`是`fork()`的一个变体，它产生的子进程刚开始暂时与父进程共享地址空间，同时将父进程阻塞。当子进程执行了`execve`或`exit`后，父进程继续实行。

__进程内页替换__

* 防止内存的过度分配，通过修改页错误的处理方法，加入页替换
* 使用modify (dirty) bit 来减少页的过度传递，只有修改后的页才会被写回
* page replacement completes separation between logical memory and physical memory - large virtual memory can be provided on a smaller physical memory
* FIFO页替换算法<br />更多的帧并不一定导致更少的页错误
* 优化算法<br />将即将最长时间没用的帧替换
* LRU算法<br />替换最不常使用的

__全局替换与局部替换__

* 全局替换<br />进程从所有帧中选择一个替换帧；一个进程可以从另一个进程中拿帧
* 局部替换<br />每个进程只能从他自己拥有的一部分分配了的帧中选择。

__页面抖动(Thrashing)__<br />如果一个进程并没有足够的帧，那么页错误率就极高。这导致了低CPU使用率、操作系统觉得应该增加多进程度、另一个进程加入了系统。页面抖动是频繁换入换出的进程。

页面抖动出现的条件：<br />$\sum$size of locality > total physical memory size

__工作集__

* $\Delta$: 工作集窗口，是一定数量（固定数量的）的页面访问
* $WSS_i$: 进程$P_i$的工作集，是在最近的$\Delta$中饮用的总页面数
  * 如果$\Delta$过小，则不会包含整个locality
  * 如果$\Delta$过大，则会包含多个locality
  * 如果$\Delta=\infty$, 则会包含整个程序
* $D=\sum WSS_i$: 总需求帧
* $m$: 总物理空间大小
* 如果$D>m$, 那么会导致窗口抖动。因此需要暂停某个进程

__处理页错误率的计划__

* 如果页错误率过低，则进程失去帧
* 如果页错误率过高，则进程获得帧

__内核部分的内存分配__

* 采用连续内存分配
* Buddy System<br />将内存分配成大小是2的幂次的块，每次分配时找最小的合适的
* Slab System
  * Slab时一个或多个连续的物理页面
  * Cache包含一个或多个Slab
  * 对于每个内核的数据结构都有一个单独的cache
  * 当cache被创建的时候，内部的object被标记为free
  * 当内核结构被存储的时候，object被标记为used
  * 如果slab内充满了used的object，那么下个object会被分配到空的slab

__预调页__

* 为了减少在进程启动时产生的大量page faults
* 将所有或部分进程需要的页预先调入

__页大小__<br />页大小的选择需要考虑到：

* 碎片
* 页表大小
* I/O overhead
* locality

### 进程间通信

* Shared Memory<br />两个进程享有一块共有的内存空间

## Chapter 10 File System Interface

__文件概念__<br />连续的逻辑地址空间

__文件的特性__

* Name
* Type
* Location
* Size
* Protection
* Time, date, and user identification

__文件系统挂载__<br />一个文件系统在被access之前必须要挂载

## Chapter 11 File System Implementation

__File Control Block (FCB)__<br />一种存储结构，包含一个文件的信息

__文件系统的层次__

* 设备驱动
* 基础文件系统<br />使用如`retrieve block 123`这类的指令翻译给设备驱动。同时管理着内存缓冲区和cache
* 文件组织模块<br />理解文件，逻辑地址和物理块
* 逻辑文件系统<br />管理元信息

__空闲空间的管理__

* Free List<br />将空闲块串成链表
* Grouping of Multiple Free Blocks
  * 第一块包含其他$n$个空闲块的地址
  * 对于每个group, 前$n-1$个块实际上是空闲的，并且最后的块包含下一个group的地址
* Address Counting
  * 块以组的形式分配和释放
  * 存储第一个空闲块的地址和接下来连续的空闲块的个数

__目录的实现方式__

* Linear list<br />以文件名作索引，值是指向该文件数据块的指针
* Hash table

__文件地址分配的方法__

* Contiguous allocation
  * 优点
    * 简单
    * 可以随机访问
  * 缺点
    * 浪费空间
    * 文件不可以增长
* Linked allocation
  * 优点
    * 简单
    * 不会浪费空间
    * 文件可以增长
  * 缺点
    * 不可以随机访问
    * 每个块包含一个指针，浪费空间
    * 块的分布散乱，需要多次disk seek
    * 不可靠
  * FAT(File Allocation Table)变种
    * 在每个加载卷中有一个表，索引为块号
    * 可以缓存
* Indexed allocation
  * 优点
    * 随机访问
    * 没有碎片化问题
  * 缺点
    * 文件大小具有上限，但有可能溢出

## Chapter 12 Mass Storage Structure

__磁盘调度__

* 访问时间
  * 寻道时间<br />磁盘将磁头移动到包含需要的扇区的柱面所需的时间。
  * 旋转延迟<br />将想要的扇区移动到磁头所需的时间。
  * 传输时间
* FCFS
* 最短寻道时间最先(SSTF)
* SCAN<br />盘臂从磁盘的一端开始，向另一端移动，不断服务请求直到达到另一端，然后返回<br />更少的饥饿
* LOOK<br />到最大的request就返回
* C-SCAN<br />类似于SCAN, 但不原路返回，而是直接返回<br />更少的饥饿
* C-LOOK<br />类似于LOOK, 但不原路返回，而是直接返回